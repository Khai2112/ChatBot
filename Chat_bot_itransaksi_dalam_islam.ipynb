{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat bot itransaksi dalam islam.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNcUcMliqbU8gUqVGxRDnp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khai2112/ChatBot/blob/main/Chat_bot_itransaksi_dalam_islam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stcmz0dTREEu"
      },
      "source": [
        "##Chat Bot sistem transaksi dalam islam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6UC2HhpRERG"
      },
      "source": [
        "Chat bot ini akan membantu untuk memberi pengetahuan kepada pengguna tentang transaksi yang di larang dan di perbolehkan dalam islam dalam bentuk pemberian penjelas singkat yang akan memberikan gambaran kepada pengguna bahwa transaksi yang dilakukan adalah kegiatan yang dibolehkan atau dilarang.\n",
        "Bot akan membantu meringkas opini ataupun hukum yang ada pada web dan dikemas menjadi lebih ringkas dan mudah dipahami.\n",
        "\n",
        "Metode ini bertujuan untuk edukasi dan menjadi fasilitas untuk melakukan, menemukan, dan menampung isu baru pada masyarakat tentang transaksi syariah.\n",
        "Dengan adanya aplikasi ini diharapkan masyarakat dapat kembali mengaplikasikan transaksi sesuai kaidah syariah dan mempermudah bagi masyarakat yang ingin mengetahui transaksi yang sedang mereka lakukan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKBZH8e1YB35"
      },
      "source": [
        "##memasukkan API dari web"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysC3LGE7YAqT"
      },
      "source": [
        "!pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rs39m6TYgw2"
      },
      "source": [
        "# Import library\n",
        "from newspaper import Article\n",
        "import random\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxPbYybKfpNM"
      },
      "source": [
        "nltk.download('punkt', quiet=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAItsKIkdtRG"
      },
      "source": [
        "article = Article('https://www.ocbcnisp.com/id/article/2021/09/27/investasi-syariah')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus = article.text\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsxaPfuVEc9W"
      },
      "source": [
        "f=open('Sukuk1.txt', 'r', errors= 'ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower() #Converts text to lowercase\n",
        "nltk.download('punkt') #Using the Punkt tokenizer\n",
        "nltk.download('wordnet') #Using the WordNet dictionary\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc) # Converts doc to list of sentences\n",
        "word_tokens = nltk.word_tokenize(raw_doc) # Convert doc to list of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMU5Bj8BGwZR"
      },
      "source": [
        "# Tokenization\n",
        "text = corpus\n",
        "sentence_list = nltk.sent_tokenize(text) #A list of senetences\n",
        "\n",
        "# Print the list of sentences\n",
        "print(sentence_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS2f3H_gHAKE"
      },
      "source": [
        "import re\n",
        "\n",
        "#replace the substrings di install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWtDSXPKHEPW"
      },
      "source": [
        "sent_tokens[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "476JR9eOHIo0"
      },
      "source": [
        "TEXT_CLEANING_RE = \"@#=-_\\S+|https?:\\S+http?\\S|{^A-Za-z}+\"\n",
        "\n",
        "def preprocessing(tweet):\n",
        "  tweet = re.sub(TEXT_CLEANING-RE,'', str(tweet).lowe()).strip()\n",
        "  tokens = []\n",
        "  for token in tweet.split():\n",
        "    if token not in tampStoplist:\n",
        "      token = stemmer.stem(token)\n",
        "      tokens.append(token)\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq8rwDrtHVt5"
      },
      "source": [
        "#a function to return a random greeting response to a users greeting\n",
        "def greeting_response(text):\n",
        "    text = text.lower()\n",
        "    \n",
        "    #Bots greeting respone\n",
        "    bot_greetings = ['halo','hai','yuhuu','*eyebrows up*']\n",
        "    \n",
        "    #Users greeting\n",
        "    user_greetings = ['Haloo','Eh iyaa Haii','Hai','greetings','wassup']\n",
        "    \n",
        "    for word in text.split():\n",
        "        if word in user_greetings:\n",
        "            return random.choice(bot_greetings)\n",
        "        \n",
        "    #Random response to greeting\n",
        "    def gratitude_response(text):\n",
        "        text=text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KRks_o-HccT"
      },
      "source": [
        " def index_sort(list_var):\n",
        "    length = len(list_var)\n",
        "    list_index = list(range(0, length))\n",
        "    \n",
        "    x = list_var        \n",
        "    for i in range(length):\n",
        "        for j in range(length):\n",
        "            if x[list_index[i]] > x[list_index[j]]:\n",
        "                #swap\n",
        "                temp = list_index[i]\n",
        "                list_index[i] = list_index[j]\n",
        "                list_index[j] = temp\n",
        "                \n",
        "    return list_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kYf-FcjHiSt"
      },
      "source": [
        "# Creat Bots Response\n",
        "def bot_response(user_input):\n",
        "    user_input=user_input.lower()\n",
        "    sentence_list.append(user_input)\n",
        "    bot_response= ''\n",
        "    cm=CountVectorizer().fit_transform(sentence_list)\n",
        "    similarity_scores=cosine_similarity(cm[-1],cm)\n",
        "    similarity_scores_list=similarity_scores.flatten()\n",
        "    index=index_sort(similarity_scores_list)\n",
        "    index=index[1:]\n",
        "    response_flag=0\n",
        "    \n",
        "    j=0\n",
        "    for i in range(len(index)):\n",
        "        if similarity_scores_list[index[i]]>0.0:\n",
        "            bot_response=bot_response+' '+sentence_list[index[i]]\n",
        "            response_flag=1\n",
        "            j=j+1\n",
        "        if j>2:\n",
        "            break\n",
        "\n",
        "        if response_flag==0:\n",
        "            bot_response=bot_response+\" \"+\"I apologize, I dont understand\"\n",
        "\n",
        "        sentence_list.remove(user_input) \n",
        "\n",
        "        return bot_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-2jVZ4mHnId"
      },
      "source": [
        "#Start Chat\n",
        "print(\"Doc Bot: Apa saja yang kamu ingin tahu dari investasi syariah\")\n",
        "\n",
        "exit_list=['exit','bye','keluar','quit', 'sampai jumpa','terimakasih']\n",
        "\n",
        "while(True):\n",
        "    user_input=input()\n",
        "    if user_input.lower() in exit_list:\n",
        "        print('Doc Bot: Bye Bye Sampai jumpa lagi')\n",
        "        break\n",
        "    else:\n",
        "        if greeting_response(user_input)!= None:\n",
        "            print('Doc Bot: '+ greeting_response(user_input))\n",
        "        else:\n",
        "            print('Doc Bot: '+ bot_response(user_input))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}